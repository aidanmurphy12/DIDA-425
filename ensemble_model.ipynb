{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ENSEMBLE MODEL\n"
      ],
      "metadata": {
        "id": "6l_DE4APDs2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you add the models shared drive into MyDrive"
      ],
      "metadata": {
        "id": "CvqA-vFcSi0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xDo0NtooSgsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "import shutil\n",
        "import torch\n",
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import os\n",
        "\n",
        "\n",
        "class Ensemble_Model():\n",
        "  def __init__(self, text):\n",
        "    self.text = text\n",
        "    self.model = None\n",
        "    self.mlp_classifier = None\n",
        "    self.svm_classifier = None\n",
        "    self.nb_classifier = None\n",
        "    self.tfidf_vec = None\n",
        "    self.tfidf_text = None\n",
        "    self.cv_text = None\n",
        "    self.cv = None\n",
        "    self.tfidf = None\n",
        "    self.tokenizer = None\n",
        "    self.tfm_pred_label = None\n",
        "    self.tfm_pred_score = None\n",
        "    self.mlp_pred_label = None\n",
        "    self.mlp_pred_score = None\n",
        "    self.svm_pred_label = None\n",
        "    self.svm_pred_score = None\n",
        "    self.nb_pred_label = None\n",
        "    self.nb_pred_score = None\n",
        "    self.model_list = None\n",
        "\n",
        "  def import_models(self):\n",
        "    if not os.path.exists(\"transformer\"):\n",
        "      shutil.copytree(\"/content/gdrive/MyDrive/425 models/transformer\", \"transformer\")\n",
        "    self.model = AutoModelForSequenceClassification.from_pretrained(\"/content/transformer\")\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(\"/content/transformer\")\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/425 models/mlp.pkl', 'rb') as f:\n",
        "      self.mlp_classifier = pickle.load(f)\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/425 models/tfidfMLP.pkl', 'rb') as f:\n",
        "      self.tfidf_vec = pickle.load(f)\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/425 models/svm.pkl', 'rb') as f:\n",
        "      self.svm_classifier = pickle.load(f)\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/425 models/vectorizer.pkl', 'rb') as f:\n",
        "      self.cv = pickle.load(f)\n",
        "\n",
        "    with open('/content/gdrive/MyDrive/425 models/tfidf.pkl', 'rb') as f:\n",
        "      self.tfidf = pickle.load(f)\n",
        "    with open('/content/gdrive/MyDrive/425 models/naivebayes.pkl', 'rb') as f:\n",
        "      self.nb_classifier = pickle.load(f)\n",
        "\n",
        "  def text_processing(self, text):\n",
        "    input_text = re.sub(r'[\\'\"‘’“”]', '', text)\n",
        "    input_text = re.sub('^.*\\(Reuters\\)\\s*-\\s*', '', input_text)\n",
        "    input_text = [input_text]\n",
        "    self.cv_text = self.cv.transform(input_text)\n",
        "    self.tfidf_text = self.tfidf.transform(self.cv_text)\n",
        "    return input_text\n",
        "\n",
        "  def define_labels(prob):\n",
        "    if prob >= 0.5:\n",
        "      pred_class = \"Real\"  # Real news\n",
        "    else:\n",
        "      pred_class = \"Fake\"  # Fake news\n",
        "    return pred_class\n",
        "\n",
        "  def transformers(self,input_text):\n",
        "    inputs = self.tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Forward pass through the model to obtain logits\n",
        "    with torch.no_grad():\n",
        "        outputs = self.model(**inputs)\n",
        "\n",
        "    # Get the predicted class label\n",
        "    tfm_pred = torch.sigmoid(outputs.logits).squeeze().tolist()  # Assuming binary classification\n",
        "    if tfm_pred >= 0.5:\n",
        "        self.tfm_pred_label = \"Real\"\n",
        "    else:\n",
        "        self.tfm_pred_label = \"Fake\"\n",
        "    self.tfm_pred_score = torch.sigmoid(outputs.logits).item()\n",
        "    return\n",
        "\n",
        "\n",
        "  def mlp(self,input_text):\n",
        "    input_tfidf = self.tfidf_vec.transform(input_text)\n",
        "    mlp_prob = self.mlp_classifier.predict_proba(input_tfidf)\n",
        "    self.mlp_pred_label = Ensemble_Model.define_labels(mlp_prob[0][1])\n",
        "    self.mlp_pred_score = mlp_prob[0][1]\n",
        "    return\n",
        "\n",
        "  def svm(self,input_text):\n",
        "    svm_prob = self.svm_classifier.decision_function(self.tfidf_text)\n",
        "    self.svm_pred_label = Ensemble_Model.define_labels(svm_prob)\n",
        "    self.svm_pred_score = svm_prob[0] if svm_prob[0]>0 else 1+svm_prob[0]\n",
        "    return\n",
        "\n",
        "  def naivebayes(self,input_text):\n",
        "    nb_prob = self.nb_classifier.predict_proba(self.tfidf_text)\n",
        "    self.nb_pred_label = Ensemble_Model.define_labels(nb_prob[0][1])\n",
        "    self.nb_pred_score = nb_prob[0][1]\n",
        "    return\n",
        "\n",
        "  def predict_list(self):\n",
        "    if self.nb_classifier == None:\n",
        "      Ensemble_Model.import_models(self)\n",
        "    text = Ensemble_Model.text_processing(self,self.text)\n",
        "    Ensemble_Model.transformers(self,text)\n",
        "    Ensemble_Model.mlp(self,text)\n",
        "    Ensemble_Model.svm(self,text)\n",
        "    Ensemble_Model.naivebayes(self,text)\n",
        "\n",
        "    self.model_list = [\"Transformers\", \"MLP\", \"SVM\", \"Naive Bayes\"]\n",
        "    self.label_list = [self.tfm_pred_label, self.mlp_pred_label, self.svm_pred_label, self.nb_pred_label]\n",
        "    self.score_list = [self.tfm_pred_score, self.mlp_pred_score, self.svm_pred_score, self.nb_pred_score]\n",
        "    return\n",
        "\n",
        "  def predict_df(self):\n",
        "    if self.model_list == None:\n",
        "      Ensemble_Model.predict_list(self)\n",
        "\n",
        "    result_df = pd.DataFrame({\"Model\": self.model_list,\n",
        "                            \"Label\": self.label_list,\n",
        "                            \"Score\": self.score_list})\n",
        "    print(result_df)\n",
        "    return\n",
        "\n",
        "  def predict(self):\n",
        "    if self.model_list == None:\n",
        "      Ensemble_Model.predict_list(self)\n",
        "\n",
        "    fake_count = self.label_list.count(\"Fake\")\n",
        "    real_count = self.label_list.count(\"Real\")\n",
        "\n",
        "    if fake_count > real_count:\n",
        "      result_label = \"Fake\"\n",
        "      result_score = statistics.mean(self.score_list[i] for i in range(4) if self.score_list[i] < 0.5)\n",
        "    elif fake_count < real_count:\n",
        "      result_label = \"Real\"\n",
        "      result_score = statistics.mean(self.score_list[i] for i in range(4) if self.score_list[i] > 0.5)\n",
        "    else:\n",
        "      result_score = statistics.mean(self.score_list[i] for i in range(4))\n",
        "      if result_score >= 0.5:\n",
        "        result_label = \"Real\"\n",
        "      else:\n",
        "        result_label = \"Fake\"\n",
        "\n",
        "    print(\"Predicted label: \", result_label)\n",
        "    print(\"Predicted score: \", result_score)\n",
        "    return"
      ],
      "metadata": {
        "id": "F2wxpiuYGZDL"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Input text \\n\" )\n",
        "Ensemble_Model(f\"\"\"{text}\"\"\").predict()\n",
        "Ensemble_Model(f\"\"\"{text}\"\"\").predict_df()"
      ],
      "metadata": {
        "id": "obx00rWrRQlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7d3d30-6dc7-48d8-cbc2-f044c2e15570"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text \n",
            "In a stunning turn of events 11 days before the 2016 presidential election, the FBI announced it is reopenning its investigation into Hillary Clinton’s email server case, by probing newly emerging emails linked to Hillary Clinton.\n",
            "Predicted label:  Fake\n",
            "Predicted score:  0.2776253280538472\n",
            "          Model Label     Score\n",
            "0  Transformers  Fake  0.499073\n",
            "1           MLP  Fake  0.142678\n",
            "2           SVM  Fake  0.225584\n",
            "3   Naive Bayes  Fake  0.243165\n"
          ]
        }
      ]
    }
  ]
}